{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.corpora import Dictionary\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_category_1(file_path):\n",
    "\n",
    "\n",
    "    f = open(file_path).read()\n",
    "    data = json.loads(f)\n",
    "    playlists = data[\"playlists\"]\n",
    "    df = pd.DataFrame(playlists)\n",
    "    train, test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "    r_test_data = {'pid' : list(test['pid']), 'name' : list(test['name']), 'num_holdouts' : list(test['num_tracks']), 'tracks' : [{} for _ in range(test.shape[0])], 'num_samples' : [0 for _ in range(test.shape[0])], 'num_tracks' : test['num_tracks']}\n",
    "    r_test = pd.DataFrame(r_test_data)\n",
    "    \n",
    "    train = train.T.to_dict().values()\n",
    "    test = test.T.to_dict().values()\n",
    "    r_test = r_test.T.to_dict().values()\n",
    "    \n",
    "    with open('./train.json', 'w+') as f:\n",
    "        f.write(json.dumps(train))\n",
    "    with open('./test_R.json', 'w+') as f:\n",
    "        f.write(json.dumps(test))\n",
    "    with open('./test.json', 'w+') as f:\n",
    "        f.write(json.dumps(r_test))\n",
    "        \n",
    "        \n",
    "make_category_1('mpd.slice.0-999.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train_set </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./train.json').read()\n",
    "data = json.loads(f)\n",
    "train_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> test_set </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./test_R.json').read()\n",
    "data = json.loads(f)\n",
    "test_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> cross validation test </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average : 5.95291695506, topic_num : 3\n",
      "average : 6.11618295956, topic_num : 5\n",
      "average : 6.11345528296, topic_num : 7\n",
      "average : 6.75875662735, topic_num : 9\n",
      "average : 5.95152494387, topic_num : 11\n",
      "average : 7.86836192657, topic_num : 13\n",
      "average : 6.79785158192, topic_num : 15\n",
      "average : 10.205701679, topic_num : 17\n",
      "average : 8.19271442626, topic_num : 19\n",
      "average : 6.27356366582, topic_num : 21\n",
      "average : 27.6587008294, topic_num : 23\n",
      "max_average : 27.6587008294, max_topic_num : 23\n"
     ]
    }
   ],
   "source": [
    "train_playlist_name = list(set(train_df['name']))\n",
    "\n",
    "train_playlist_name = [train_playlist_name[i:i + len(train_playlist_name)/10] \n",
    "                       for i in xrange(0, len(train_playlist_name), len(train_playlist_name)/10)]\n",
    "topic_num = 3\n",
    "max = 0\n",
    "max_topic_num = 0\n",
    "for idx in range(0, len(train_playlist_name)):\n",
    "    #0~9 까지 validation\n",
    "    validation_texts = [[word for word in name.lower().split()]for name in train_playlist_name[idx]]\n",
    "    \n",
    "    #train_set after slice\n",
    "    train_texts = []\n",
    "    for tidx in range(0,len(train_playlist_name)):\n",
    "        if(tidx == idx):\n",
    "            continue\n",
    "        train_texts.extend(train_playlist_name[tidx])\n",
    "    train_texts = [[word for word in name.lower().split()]\n",
    "                  for name in train_texts]\n",
    "    \n",
    "    #LDA model create\n",
    "    dictionary = corpora.Dictionary(train_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in train_texts]\n",
    "    model = models.ldamodel.LdaModel(corpus = corpus, id2word = dictionary,\n",
    "                                    num_topics = topic_num, random_state = 0,\n",
    "                                    chunksize = 2000, passes = 10)\n",
    "    \n",
    "    #document 별 topic 다항분포 train\n",
    "    train_dic = {}\n",
    "    for idx in range(0, len(train_texts)):\n",
    "        t = train_texts[idx]\n",
    "        bow = dictionary.doc2bow(t)\n",
    "        get_document_topics = tuple(model.get_document_topics(bow))\n",
    "        name = ' '.join(t)\n",
    "        train_dic[name] = dict(get_document_topics)\n",
    "    train_dic = pd.DataFrame(train_dic)\n",
    "    #print train_dic\n",
    "    \n",
    "    #document 별 topic 다항분포 validation\n",
    "    validation_dic = {}\n",
    "    for idx in range(0, len(validation_texts)):\n",
    "        t = validation_texts[idx]\n",
    "        bow = dictionary.doc2bow(t)\n",
    "        get_document_topics = tuple(model.get_document_topics(bow))\n",
    "        name = ' '.join(t)\n",
    "        validation_dic[name] = dict(get_document_topics)\n",
    "    validation_dic =pd.DataFrame(validation_dic).T\n",
    "    #print validation_dic\n",
    "    \n",
    "    result = []\n",
    "    for trainName in train_dic.columns:\n",
    "        idx = 0\n",
    "        #c = 0\n",
    "        denominator = 0\n",
    "        numeratorA = 0\n",
    "        numeratorB = 0\n",
    "        columns_ones = []\n",
    "        for valName in validation_dic.index:\n",
    "            for idx in range(0, topic_num):\n",
    "                #c += pow(train_dic[trainName][idx] - validation_dic[idx][valName], 2)\n",
    "                denominator += (train_dic[trainName][idx] * validation_dic[idx][valName])\n",
    "                numeratorA += pow(train_dic[trainName][idx],2)\n",
    "                numeratorB += pow(validation_dic[idx][valName],2)\n",
    "            #c = 1/(1+sqrt(c))\n",
    "            c = denominator / (sqrt(numeratorA) * sqrt(numeratorB))\n",
    "            columns_ones.append(c)\n",
    "        result.append(columns_ones)\n",
    "    #train_playlist X validation_playlist_name 유클리디안 거리 행렬 생성    \n",
    "    result = pd.DataFrame(result, columns = validation_dic.index, index = train_dic.columns)\n",
    "    \n",
    "    #validation_Set evaluation\n",
    "    count = 0\n",
    "    c = 0;\n",
    "    for name in result.columns:\n",
    "        #test_playlist_name 과 거리가 가까운 train_playlist_name 상위 10개 도출\n",
    "        result_playlist_name = result[name].sort_values(ascending = False).head(10).index\n",
    "        #print count\n",
    "        count+=1\n",
    "    \n",
    "        #test_playlist 생성\n",
    "        validation_playlist = []\n",
    "        for idx in range(0, len(train_df['name'])):\n",
    "            if(train_df['name'][idx].lower() == name):\n",
    "                val_track_uri = pd.DataFrame(train_df['tracks'][idx])\n",
    "                val_playlist = list(val_track_uri['track_uri'])\n",
    "        #print len(test_playlist)        \n",
    "        if(len(val_playlist) == 0):\n",
    "            continue\n",
    "            \n",
    "        #비교할 train_playlist 생성\n",
    "        train_playlist = []\n",
    "        for train_name in result_playlist_name:\n",
    "            for idx in range(0,len(train_df['name'])):\n",
    "                if(train_df['name'][idx].lower() == train_name):\n",
    "                    df = pd.DataFrame(train_df['tracks'][idx])\n",
    "                    train_playlist += list(df['track_uri'])\n",
    "                    if(len(train_playlist) >= 500):\n",
    "                        continue\n",
    "                    elif(len(train_playlist) + len(list(df['track_uri'])) >= 500):\n",
    "                        temp = list(df['track_uri'])\n",
    "                        train_playlist += temp[:-(len(train_playlist)-500)]\n",
    "                    else:\n",
    "                        train_playlist += list(df['track_uri'])\n",
    "        #print len(train_playlist)      \n",
    "        #r-precision 계산\n",
    "        c += 1.0 *len(set(train_playlist).intersection(set(val_playlist)))/len(set(val_playlist)) *100\n",
    "    \n",
    "    #avarage result\n",
    "    c = 1.0 * c/(count)\n",
    "    print (\"average : {}, topic_num : {}\".format(c, topic_num))\n",
    "    if max < c:\n",
    "        max = c\n",
    "        max_topic_num = topic_num\n",
    "        maxModel = model\n",
    "\n",
    "    topic_num += 2 #3,5,7,9,11,13,15,....\n",
    "print (\"max_average : {}, max_topic_num : {}\".format(max, max_topic_num)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> test! </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test_playlist length :62\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 4.91803278689\n",
      "count : 1\n",
      "1\n",
      "test_playlist length :130\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 4.91803278689\n",
      "count : 2\n",
      "2\n",
      "test_playlist length :57\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 8.42680471671\n",
      "count : 3\n",
      "3\n",
      "test_playlist length :40\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 8.42680471671\n",
      "count : 4\n",
      "4\n",
      "test_playlist length :72\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 18.1490269389\n",
      "count : 5\n",
      "5\n",
      "test_playlist length :19\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 23.4121848337\n",
      "count : 6\n",
      "6\n",
      "test_playlist length :0\n",
      "6\n",
      "test_playlist length :29\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 26.8604606957\n",
      "count : 7\n",
      "7\n",
      "test_playlist length :0\n",
      "7\n",
      "test_playlist length :35\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 32.57474641\n",
      "count : 8\n",
      "8\n",
      "test_playlist length :53\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 36.3483313157\n",
      "count : 9\n",
      "9\n",
      "test_playlist length :111\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 39.984694952\n",
      "count : 10\n",
      "10\n",
      "test_playlist length :35\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 48.5561235235\n",
      "count : 11\n",
      "11\n",
      "test_playlist length :99\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 12\n",
      "12\n",
      "test_playlist length :19\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 13\n",
      "13\n",
      "test_playlist length :64\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 14\n",
      "14\n",
      "test_playlist length :32\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 15\n",
      "15\n",
      "test_playlist length :90\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 16\n",
      "16\n",
      "test_playlist length :50\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 17\n",
      "17\n",
      "test_playlist length :166\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 68.7581437255\n",
      "count : 18\n",
      "18\n",
      "test_playlist length :51\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 72.6797123529\n",
      "count : 19\n",
      "19\n",
      "test_playlist length :77\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 76.627080774\n",
      "count : 20\n",
      "20\n",
      "test_playlist length :111\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 78.4288825758\n",
      "count : 21\n",
      "21\n",
      "test_playlist length :30\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 78.4288825758\n",
      "count : 22\n",
      "22\n",
      "test_playlist length :63\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 78.4288825758\n",
      "count : 23\n",
      "23\n",
      "test_playlist length :30\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 88.4288825758\n",
      "count : 24\n",
      "24\n",
      "test_playlist length :12\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 105.095549242\n",
      "count : 25\n",
      "25\n",
      "test_playlist length :25\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 109.095549242\n",
      "count : 26\n",
      "26\n",
      "test_playlist length :28\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 116.238406385\n",
      "count : 27\n",
      "27\n",
      "test_playlist length :138\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 119.861594791\n",
      "count : 28\n",
      "28\n",
      "test_playlist length :66\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 122.891897821\n",
      "count : 29\n",
      "29\n",
      "test_playlist length :0\n",
      "29\n",
      "test_playlist length :22\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 122.891897821\n",
      "count : 30\n",
      "30\n",
      "test_playlist length :42\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 125.330922212\n",
      "count : 31\n",
      "31\n",
      "test_playlist length :50\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 133.330922212\n",
      "count : 32\n",
      "32\n",
      "test_playlist length :31\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 133.330922212\n",
      "count : 33\n",
      "33\n",
      "test_playlist length :0\n",
      "33\n",
      "test_playlist length :59\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 151.974990008\n",
      "count : 34\n",
      "34\n",
      "test_playlist length :18\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 168.641656675\n",
      "count : 35\n",
      "35\n",
      "test_playlist length :0\n",
      "35\n",
      "test_playlist length :0\n",
      "35\n",
      "test_playlist length :10\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 168.641656675\n",
      "count : 36\n",
      "36\n",
      "test_playlist length :73\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 180.970423798\n",
      "count : 37\n",
      "37\n",
      "test_playlist length :0\n",
      "37\n",
      "test_playlist length :0\n",
      "37\n",
      "test_playlist length :36\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 195.256138084\n",
      "count : 38\n",
      "38\n",
      "test_playlist length :192\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 199.943638084\n",
      "count : 39\n",
      "39\n",
      "test_playlist length :235\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 203.822948429\n",
      "count : 40\n",
      "40\n",
      "test_playlist length :0\n",
      "40\n",
      "test_playlist length :198\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 203.822948429\n",
      "count : 41\n",
      "41\n",
      "test_playlist length :34\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 215.94416055\n",
      "count : 42\n",
      "42\n",
      "test_playlist length :75\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 218.646863253\n",
      "count : 43\n",
      "43\n",
      "test_playlist length :71\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 218.646863253\n",
      "count : 44\n",
      "44\n",
      "test_playlist length :79\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 232.749427355\n",
      "count : 45\n",
      "45\n",
      "test_playlist length :52\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 232.749427355\n",
      "count : 46\n",
      "46\n",
      "test_playlist length :40\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 235.249427355\n",
      "count : 47\n",
      "47\n",
      "test_playlist length :79\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 237.916094022\n",
      "count : 48\n",
      "48\n",
      "test_playlist length :44\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 244.73427584\n",
      "count : 49\n",
      "49\n",
      "test_playlist length :20\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 244.73427584\n",
      "count : 50\n",
      "50\n",
      "test_playlist length :94\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 250.169058449\n",
      "count : 51\n",
      "51\n",
      "test_playlist length :18\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 255.724614004\n",
      "count : 52\n",
      "52\n",
      "test_playlist length :115\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 256.609569757\n",
      "count : 53\n",
      "53\n",
      "test_playlist length :10\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 256.609569757\n",
      "count : 54\n",
      "54\n",
      "test_playlist length :64\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 256.609569757\n",
      "count : 55\n",
      "55\n",
      "test_playlist length :203\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 256.609569757\n",
      "count : 56\n",
      "56\n",
      "test_playlist length :24\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 256.609569757\n",
      "count : 57\n",
      "57\n",
      "test_playlist length :55\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 267.518660666\n",
      "count : 58\n",
      "58\n",
      "test_playlist length :158\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 272.581951805\n",
      "count : 59\n",
      "59\n",
      "test_playlist length :63\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 272.581951805\n",
      "count : 60\n",
      "60\n",
      "test_playlist length :68\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 274.05254004\n",
      "count : 61\n",
      "61\n",
      "test_playlist length :156\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 275.342862621\n",
      "count : 62\n",
      "62\n",
      "test_playlist length :120\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 280.384879428\n",
      "count : 63\n",
      "63\n",
      "test_playlist length :59\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 283.774709936\n",
      "count : 64\n",
      "64\n",
      "test_playlist length :9\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 283.774709936\n",
      "count : 65\n",
      "65\n",
      "test_playlist length :5\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 283.774709936\n",
      "count : 66\n",
      "66\n",
      "test_playlist length :105\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 288.582402244\n",
      "count : 67\n",
      "67\n",
      "test_playlist length :16\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 313.582402244\n",
      "count : 68\n",
      "68\n",
      "test_playlist length :31\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 313.582402244\n",
      "count : 69\n",
      "69\n",
      "test_playlist length :9\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 313.582402244\n",
      "count : 70\n",
      "70\n",
      "test_playlist length :33\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 322.673311335\n",
      "count : 71\n",
      "71\n",
      "test_playlist length :24\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 326.839978001\n",
      "count : 72\n",
      "72\n",
      "test_playlist length :35\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 332.554263716\n",
      "count : 73\n",
      "73\n",
      "test_playlist length :69\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 332.554263716\n",
      "count : 74\n",
      "74\n",
      "test_playlist length :44\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 334.826990988\n",
      "count : 75\n",
      "75\n",
      "test_playlist length :145\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 337.643892397\n",
      "count : 76\n",
      "76\n",
      "test_playlist length :8\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 337.643892397\n",
      "count : 77\n",
      "77\n",
      "test_playlist length :28\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 337.643892397\n",
      "count : 78\n",
      "78\n",
      "test_playlist length :33\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 340.674195427\n",
      "count : 79\n",
      "79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_playlist length :205\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 340.674195427\n",
      "count : 80\n",
      "80\n",
      "test_playlist length :17\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 346.556548368\n",
      "count : 81\n",
      "81\n",
      "test_playlist length :16\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 346.556548368\n",
      "count : 82\n",
      "82\n",
      "test_playlist length :23\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 346.556548368\n",
      "count : 83\n",
      "83\n",
      "test_playlist length :26\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 350.402702214\n",
      "count : 84\n",
      "84\n",
      "test_playlist length :189\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 352.006980289\n",
      "count : 85\n",
      "85\n",
      "test_playlist length :150\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 356.673646956\n",
      "count : 86\n",
      "86\n",
      "test_playlist length :73\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 356.673646956\n",
      "count : 87\n",
      "87\n",
      "test_playlist length :29\n",
      "total_train_playlist : 500\n",
      "r-precision summation: 356.673646956\n",
      "count : 88\n",
      "total average : 4.0531096245\n"
     ]
    }
   ],
   "source": [
    "train_playlist_name = list(set(train_df['name']))\n",
    "test_playlist_name = list(set(test_df['name']))\n",
    "\n",
    "#train_playlist_name\n",
    "#소문자로\n",
    "train_texts = [[word for word in name.lower().split()]\n",
    "         for name in train_playlist_name]\n",
    "\n",
    "#test_playlist_name\n",
    "#역시 소문자로\n",
    "test_texts = [[word for word in name.lower().split()]\n",
    "         for name in test_playlist_name]\n",
    "\n",
    "topic_num = max_topic_num\n",
    " #LDA model create\n",
    "#dictionary = corpora.Dictionary(train_texts)\n",
    "#corpus = [dictionary.doc2bow(text) for text in train_texts]\n",
    "#model = models.ldamodel.LdaModel(corpus = corpus, id2word = dictionary,\n",
    "#                                   num_topics = topic_num, random_state = 0,\n",
    "#                                    chunksize = 20000, passes = 10)\n",
    "model = maxModel   \n",
    "    #document 별 topic 다항분포 train\n",
    "train_dic = {}\n",
    "for idx in range(0, len(train_texts)):\n",
    "    t = train_texts[idx]\n",
    "    bow = dictionary.doc2bow(t)\n",
    "    get_document_topics = tuple(model.get_document_topics(bow))\n",
    "    name = ' '.join(t)\n",
    "    train_dic[name] = dict(get_document_topics)\n",
    "train_dic = pd.DataFrame(train_dic)\n",
    "#print train_dic\n",
    "    \n",
    "    #document 별 topic 다항분포 validation\n",
    "test_dic = {}\n",
    "for idx in range(0, len(test_texts)):\n",
    "    t = test_texts[idx]\n",
    "    bow = dictionary.doc2bow(t)\n",
    "    get_document_topics = tuple(model.get_document_topics(bow))\n",
    "    name = ' '.join(t)\n",
    "    test_dic[name] = dict(get_document_topics)\n",
    "test_dic =pd.DataFrame(test_dic).T\n",
    "#print validation_dic\n",
    "    \n",
    "result = []\n",
    "for trainName in train_dic.columns:\n",
    "    idx = 0\n",
    "    c = 0\n",
    "    columns_ones = []\n",
    "    for testName in test_dic.index:\n",
    "        for idx in range(0, topic_num):\n",
    "            #c += pow(train_dic[trainName][idx] - test_dic[idx][testName], 2)\n",
    "            denominator += (train_dic[trainName][idx] * test_dic[idx][testName])\n",
    "            numeratorA += pow(train_dic[trainName][idx],2)\n",
    "            numeratorB += pow(test_dic[idx][testName],2)\n",
    "        #c = 1/(1+sqrt(c))\n",
    "        c = 1.0 *denominator / (sqrt(numeratorA) * sqrt(numeratorB))\n",
    "        columns_ones.append(c)\n",
    "    result.append(columns_ones)\n",
    "#train_playlist X validation_playlist_name 코사인 유사도 행렬 생성    \n",
    "result = pd.DataFrame(result, columns = test_dic.index, index = train_dic.columns)\n",
    "#print result   \n",
    "    #validation_Set evaluation\n",
    "count = 0\n",
    "c = 0;\n",
    "for name in result.columns:\n",
    "    #test_playlist_name 과 거리가 가까운 train_playlist_name 상위 10개 도출\n",
    "    result_playlist_name = result[name].sort_values(ascending = False).head(10).index\n",
    "    print count\n",
    "    \n",
    "    #test_playlist 생성\n",
    "    test_playlist = []\n",
    "    for idx in range(0, len(test_df['name'])):\n",
    "        if(test_df['name'][idx].lower() == name):\n",
    "            test_track_uri = pd.DataFrame(test_df['tracks'][idx])\n",
    "            test_playlist = list(test_track_uri['track_uri'])\n",
    "    print \"test_playlist length :{}\".format(len(test_playlist))        \n",
    "    if(len(test_playlist) == 0):\n",
    "        continue\n",
    "            \n",
    "        #비교할 train_playlist 생성\n",
    "    train_playlist = []\n",
    "    for train_name in result_playlist_name:\n",
    "        for idx in range(0,len(train_df['name'])):\n",
    "            if(train_df['name'][idx].lower() == train_name):\n",
    "                df = pd.DataFrame(train_df['tracks'][idx])\n",
    "                temp =[]\n",
    "                if(len(train_playlist) >= 500):\n",
    "                    continue\n",
    "                elif(len(train_playlist) + len(list(df['track_uri'])) >= 500):\n",
    "                    temp = list(df['track_uri'])\n",
    "                    train_playlist += temp[:-(len(train_playlist)-500)]\n",
    "                else:\n",
    "                    train_playlist += list(df['track_uri'])\n",
    "    print \"total_train_playlist : {}\".format(len(train_playlist))      \n",
    "    #r-precision 계산\n",
    "    #if(len(set(train_playlist).intersection(set(test_playlist))) == 0):\n",
    "    #    continue\n",
    "    c += 1.0 *len(set(train_playlist).intersection(set(test_playlist)))/len(set(test_playlist)) *100\n",
    "    count+=1\n",
    "    print \"r-precision summation: {}\".format(c)\n",
    "    print \"count : {}\".format(count)\n",
    "    #avarage result\n",
    "c = 1.0 * c/(count)\n",
    "print \"total average : {}\".format(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
