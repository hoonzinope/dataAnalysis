{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpd.slice.728000-728999.json\n",
      "mpd.slice.955000-955999.json\n",
      "mpd.slice.877000-877999.json\n",
      "mpd.slice.989000-989999.json\n",
      "mpd.slice.564000-564999.json\n",
      "mpd.slice.679000-679999.json\n",
      "mpd.slice.166000-166999.json\n",
      "mpd.slice.158000-158999.json\n",
      "mpd.slice.936000-936999.json\n",
      "mpd.slice.138000-138999.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path_dir = '/root/team2/data_test'\n",
    "file_list = os.listdir(path_dir)\n",
    "\n",
    "import json\n",
    "head = []\n",
    "count = 0\n",
    "for f in file_list:\n",
    "    print f\n",
    "    with open(\"/root/team2/data_test/\"+f, 'rb') as infile:\n",
    "        file_data = json.load(infile)\n",
    "        playlist = file_data['playlists']\n",
    "        df = pd.DataFrame(playlist)\n",
    "        head += [df]\n",
    "        count += 1\n",
    "        if(count == 10):\n",
    "            break;\n",
    "df = pd.concat(head, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0th try....\n",
      "precision : 0.00514418386411\n",
      "recall : 0.0319558475277\n",
      "f1score : 0.00886181218985\n",
      "\n",
      "1th try....\n",
      "precision : 0.0050826451371\n",
      "recall : 0.0319026447357\n",
      "f1score : 0.00876834128835\n",
      "\n",
      "2th try....\n",
      "precision : 0.00520082532166\n",
      "recall : 0.0325203072486\n",
      "f1score : 0.00896751639637\n",
      "\n",
      "3th try....\n",
      "precision : 0.00459033778291\n",
      "recall : 0.028804960723\n",
      "f1score : 0.00791874937238\n",
      "\n",
      "4th try....\n",
      "precision : 0.0050061825143\n",
      "recall : 0.0329457245699\n",
      "f1score : 0.00869164808487\n",
      "\n",
      "5th try....\n",
      "precision : 0.00519476120835\n",
      "recall : 0.0326158150339\n",
      "f1score : 0.00896211523629\n",
      "\n",
      "6th try....\n",
      "precision : 0.00491980053537\n",
      "recall : 0.0309402567283\n",
      "f1score : 0.00848966249536\n",
      "\n",
      "7th try....\n",
      "precision : 0.00481454322155\n",
      "recall : 0.0349592597008\n",
      "f1score : 0.00846350383701\n",
      "\n",
      "8th try....\n",
      "precision : 0.00474158024104\n",
      "recall : 0.0343100158783\n",
      "f1score : 0.00833173081383\n",
      "\n",
      "9th try....\n",
      "precision : 0.00463577573341\n",
      "recall : 0.0315968007466\n",
      "f1score : 0.00808530313792\n",
      "minF1score : 0.00791874937238, maxF1score: 0.00896751639637, averageF1score: 0.00855403828522\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "k = 10\n",
    "topic_num = 7\n",
    "kfold = [df[i:i + len(df)/k] for i in xrange(0, len(df), len(df)/k)]\n",
    "\n",
    "max_f1score = 0\n",
    "min_f1score = 1\n",
    "average_f1score = 0\n",
    "for idx in range(0, k):\n",
    "    print \"\\n{}th try....\".format(idx)\n",
    "    test_df = kfold[idx].reset_index()\n",
    "    \n",
    "    train_df = []\n",
    "    for tidx in range(0, k):\n",
    "        if(tidx == idx):\n",
    "            continue\n",
    "        train_df += [kfold[tidx]]\n",
    "    train_df = pd.concat(train_df, ignore_index = True)\n",
    "    \n",
    "    train_playlist_name = list(set(train_df['name']))\n",
    "    test_playlist_name = list(set(test_df['name']))\n",
    "    \n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    count = 0\n",
    "    for name in test_playlist_name:\n",
    "        count += 1\n",
    "        #print count\n",
    "        test_playlist = []\n",
    "        for idx in range(0, len(test_df['name'])):\n",
    "            if(test_df['name'][idx] == name):\n",
    "                test = pd.DataFrame(test_df['tracks'][idx])\n",
    "                test_playlist += list(test['track_uri'])\n",
    "\n",
    "        random_train_playlist_name = random.sample(train_playlist_name, 10)\n",
    "        train_playlist = []\n",
    "        for train_name in random_train_playlist_name:\n",
    "            for idx in range(0, len(train_df['name'])):\n",
    "                if(train_df['name'][idx] == train_name):\n",
    "                    train = pd.DataFrame(train_df['tracks'][idx])\n",
    "                    temp =[]\n",
    "                    if(len(train_playlist) >= 500):\n",
    "                        continue\n",
    "                    elif(len(train_playlist) + len(list(train['track_uri'])) >= 500):\n",
    "                        temp = list(train['track_uri'])\n",
    "                        train_playlist += temp[:-(len(train_playlist)-500)]\n",
    "                    else:\n",
    "                        train_playlist += list(train['track_uri'])\n",
    "\n",
    "        precision += 1.0 *len(set(train_playlist).intersection(set(test_playlist)))/len(set(train_playlist))\n",
    "        recall += 1.0 * len(set(train_playlist).\n",
    "                                intersection(set(test_playlist)))/len(set(test_playlist))\n",
    "\n",
    "    precision = 1.0 * precision/ (count)\n",
    "    recall = 1.0 * recall / count\n",
    "    f1score = (2 * precision * recall) / (precision + recall)\n",
    "    print \"precision : {}\\nrecall : {}\\nf1score : {}\".format(precision, recall, f1score)\n",
    "    \n",
    "    if(min_f1score > f1score):\n",
    "        min_f1score = f1score\n",
    "    if(max_f1score < f1score):\n",
    "        max_f1score = f1score\n",
    "    \n",
    "    average_f1score += f1score\n",
    "\n",
    "average_f1score = average_f1score/10\n",
    "print \"minF1score : {}, maxF1score: {}, averageF1score: {}\".format(min_f1score, max_f1score, average_f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
